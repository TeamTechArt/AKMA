{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lC45WUtANxZ8"
   },
   "source": [
    "# StyleGAN3 Reactive Audio\n",
    "\n",
    "By Derrick Schultz for the StyleGAN2 Deep Dive class.\n",
    "\n",
    "This notebook shows one basic example of how to alter your StyleGAN2 vectors with audio. There are lots of different techniques to explore in this, but this is one simple way.\n",
    "\n",
    "Big thanks to Robert Luxemburg who provided the basis for a lot of this code with [this gist](https://gist.github.com/rolux/48f1da6cf2bc6ca5833dbacbf852b348)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m788lAb7OtJt"
   },
   "source": [
    "## Installation\n",
    "\n",
    "First let’s install the repos and dependencies needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0QlWt43Lg5j",
    "outputId": "39105ad4-2546-4873-f1ae-fc163b64ba17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 18 07:33:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    37W / 300W |      0MiB / 16384MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 시작하기 전에 GPU 부터 확인하시오! K80 받으면 차라리 꺼라!\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSVmbuBZbRyp",
    "outputId": "79bd58c3-d71b-472b-fd73-cf863c24bfe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-18 07:17:22--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220218%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220218T071722Z&X-Amz-Expires=300&X-Amz-Signature=96406923cb64ca59f70d9542a11ab890e2cfe406f72aa49d2913cc49f1ff87fb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-02-18 07:17:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220218%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220218T071722Z&X-Amz-Expires=300&X-Amz-Signature=96406923cb64ca59f70d9542a11ab890e2cfe406f72aa49d2913cc49f1ff87fb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 77854 (76K) [application/octet-stream]\n",
      "Saving to: ‘ninja-linux.zip’\n",
      "\n",
      "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-02-18 07:17:22 (572 KB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
      "\n",
      "Archive:  ninja-linux.zip\n",
      "  inflating: /usr/local/bin/ninja    \n",
      "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
     ]
    }
   ],
   "source": [
    "# 초기 다운로드 해야하는 거여서 다른 분들이 사용하실 때에는 \n",
    "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip # !wget : Web GET의 약어로 웹 상의 파일을 다운로드할 때 사용하는 명령어 -> ninja-linux.zip 다운로드\n",
    "!sudo unzip ninja-linux.zip -d /usr/local/bin/ # !sudo 현재 계정에서 root 권한을 이용하여 명령어를 실행할 때 사용 -> ninja-linux.zip 을 unzip\n",
    "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force # 위에서 설치한 특정 패키지를 설치한 후 이 코드를 통해 명령어로 등록을 할 수 있습니다. (참고링크 : https://www.whatwant.com/entry/update-alternatives-%EC%97%AC%EB%9F%AC-%EB%B2%84%EC%A0%84%EC%9D%98-%ED%8C%A8%ED%82%A4%EC%A7%80-%EA%B4%80%EB%A6%AC%ED%95%98%EA%B8%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5n6wTwbFOofN",
    "outputId": "cf7bde8e-618c-4747-af56-169800af4c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'stylegan3' already exists and is not an empty directory.\n",
      "Requirement already satisfied: opensimplex in ./anaconda3/lib/python3.9/site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.20 in ./anaconda3/lib/python3.9/site-packages (from opensimplex) (1.20.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/roughideal_gmail_com/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "/home/roughideal_gmail_com/stylegan3\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/dvschultz/stylegan3.git # use this fork to get interpolation functions\n",
    "# !pip install opensimplex # needed for noise interpolation\n",
    "%cd stylegan3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습을 위한 진행\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.3.0.tar.gz (13 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from gdown) (2.26.0)\n",
      "Requirement already satisfied: filelock in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from gdown) (3.3.1)\n",
      "Requirement already satisfied: tqdm in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from gdown) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (3.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/roughideal_gmail_com/anaconda3/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.3.0-py3-none-any.whl size=14412 sha256=8aac3537f29a32aced166dac4d18bbfcfda7d7c05dcd348cde6c79ed1925b12a\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/e9/14/fc7fae555955433aac1bddc5c8212fc8dcf9e3b7edbc1fbbce\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/roughideal_gmail_com/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-A1BV83geagAPAcsm8OH__a3Adr8rzAi\n",
      "To: /home/roughideal_gmail_com/stylegan3/wave-256x256.zip\n",
      "100%|███████████████████████████████████████| 7.91G/7.91G [01:00<00:00, 131MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --fuzzy https://drive.google.com/file/d/1-A1BV83geagAPAcsm8OH__a3Adr8rzAi/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14UGDDOusZ9TMb-pOrF0PAjMGVWLSAii1\n",
      "To: /home/roughideal_gmail_com/stylegan3/lhq-256-stylegan3-t-25Mimg.pkl\n",
      "100%|█████████████████████████████████████████| 343M/343M [00:02<00:00, 117MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --fuzzy https://drive.google.com/file/d/14UGDDOusZ9TMb-pOrF0PAjMGVWLSAii1/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 4\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512,\n",
      "    \"magnitude_ema_beta\": 0.9994456359721023\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
      "    \"block_kwargs\": {\n",
      "      \"freeze_layers\": 0\n",
      "    },\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.0025\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.002\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 10.0,\n",
      "    \"blur_init_sigma\": 0\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"num_workers\": 3\n",
      "  },\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"/home/roughideal_gmail_com/stylegan3/dataset\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 40146,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 256,\n",
      "    \"random_seed\": 0\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"batch_size\": 16,\n",
      "  \"batch_gpu\": 16,\n",
      "  \"metrics\": [],\n",
      "  \"total_kimg\": 1,\n",
      "  \"kimg_per_tick\": 1,\n",
      "  \"image_snapshot_ticks\": 1,\n",
      "  \"network_snapshot_ticks\": 1,\n",
      "  \"random_seed\": 0,\n",
      "  \"ema_kimg\": 5.0,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"ada_target\": 0.6,\n",
      "  \"resume_pkl\": \"/home/roughideal_gmail_com/stylegan3/lhq-256-stylegan3-t-25Mimg.pkl\",\n",
      "  \"ada_kimg\": 100,\n",
      "  \"ema_rampup\": null,\n",
      "  \"run_dir\": \"/home/roughideal_gmail_com/result/00005-stylegan3-t-dataset-gpus1-batch16-gamma10-first_train\"\n",
      "}\n",
      "\n",
      "Output directory:    /home/roughideal_gmail_com/result/00005-stylegan3-t-dataset-gpus1-batch16-gamma10-first_train\n",
      "Number of GPUs:      1\n",
      "Batch size:          16 images\n",
      "Training duration:   1 kimg\n",
      "Dataset path:        /home/roughideal_gmail_com/stylegan3/dataset\n",
      "Dataset size:        40146 images\n",
      "Dataset resolution:  256\n",
      "Dataset labels:      False\n",
      "Dataset x-flips:     False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "\n",
      "Num images:  40146\n",
      "Image shape: [3, 256, 256]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Resuming from \"/home/roughideal_gmail_com/stylegan3/lhq-256-stylegan3-t-25Mimg.pkl\"\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
      "\n",
      "Generator                     Parameters  Buffers  Output shape         Datatype\n",
      "---                           ---         ---      ---                  ---     \n",
      "mapping.fc0                   262656      -        [16, 512]            float32 \n",
      "mapping.fc1                   262656      -        [16, 512]            float32 \n",
      "mapping.fc2                   262656      -        [16, 512]            float32 \n",
      "mapping.fc3                   262656      -        [16, 512]            float32 \n",
      "mapping                       -           512      [16, 16, 512]        float32 \n",
      "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
      "synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n",
      "synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n",
      "synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
      "synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n",
      "synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
      "synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n",
      "synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
      "synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n",
      "synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n",
      "synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n",
      "synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n",
      "synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n",
      "synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n",
      "synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n",
      "synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n",
      "synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n",
      "synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n",
      "synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n",
      "synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n",
      "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
      "synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n",
      "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
      "synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n",
      "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
      "synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n",
      "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
      "synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n",
      "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
      "synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n",
      "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
      "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
      "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
      "---                           ---         ---      ---                  ---     \n",
      "Total                         28997445    2456     -                    -       \n",
      "\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
      "---            ---         ---      ---                  ---     \n",
      "b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n",
      "b256.skip      32768       16       [16, 256, 128, 128]  float16 \n",
      "b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n",
      "b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n",
      "b256           -           16       [16, 256, 128, 128]  float16 \n",
      "b128.skip      131072      16       [16, 512, 64, 64]    float16 \n",
      "b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n",
      "b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n",
      "b128           -           16       [16, 512, 64, 64]    float16 \n",
      "b64.skip       262144      16       [16, 512, 32, 32]    float16 \n",
      "b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n",
      "b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n",
      "b64            -           16       [16, 512, 32, 32]    float16 \n",
      "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
      "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
      "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
      "b32            -           16       [16, 512, 16, 16]    float16 \n",
      "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
      "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
      "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
      "b16            -           16       [16, 512, 8, 8]      float32 \n",
      "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
      "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
      "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
      "b8             -           16       [16, 512, 4, 4]      float32 \n",
      "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
      "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
      "b4.fc          4194816     -        [16, 512]            float32 \n",
      "b4.out         513         -        [16, 1]              float32 \n",
      "---            ---         ---      ---                  ---     \n",
      "Total          28864129    416      -                    -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "Initializing logs...\n",
      "Training for 1 kimg...\n",
      "\n",
      "tick 0     kimg 0.0      time 1m 41s       sec/tick 39.4    sec/kimg 2463.85 maintenance 61.4   cpumem 4.62   gpumem 10.75  reserved 11.77  augment 0.000\n",
      "tick 1     kimg 1.0      time 4m 34s       sec/tick 148.1   sec/kimg 149.32  maintenance 25.3   cpumem 4.75   gpumem 9.95   reserved 11.78  augment 0.009\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "!python train.py --outdir=/home/roughideal_gmail_com/result --cfg=stylegan3-t --data=/home/roughideal_gmail_com/stylegan3/dataset --desc=first_train --metrics=none --map-depth=4 --gpus=1 --batch=16 --gamma=10 --mirror=0 --kimg=1 --aug=ada --tick=1 --snap=1 --resume=/home/roughideal_gmail_com/stylegan3/lhq-256-stylegan3-t-25Mimg.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/roughideal_gmail_com/stylegan3\n"
     ]
    }
   ],
   "source": [
    "%cd /home/roughideal_gmail_com/stylegan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile       dataset_tool.py  gen_images.py                   \u001b[0m\u001b[01;34mtorch_utils\u001b[0m/\r\n",
      "LICENSE.txt      \u001b[01;34mdnnlib\u001b[0m/          gen_video.py                    train.py\r\n",
      "README.md        \u001b[01;34mdocs\u001b[0m/            \u001b[01;34mgui_utils\u001b[0m/                      \u001b[01;34mtraining\u001b[0m/\r\n",
      "avg_spectra.py   environment.yml  legacy.py                       visualizer.py\r\n",
      "calc_metrics.py  \u001b[01;34mframes_test03\u001b[0m/   lhq-256-stylegan3-t-25Mimg.pkl  \u001b[01;34mviz\u001b[0m/\r\n",
      "\u001b[01;34mdataset\u001b[0m/         \u001b[01;32mgdown.pl\u001b[0m*        \u001b[01;34mmetrics\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DWRv9BWTr4A"
   },
   "source": [
    "## Upload an audio file\n",
    "\n",
    "I recommend uploading something simple to start with (think a single instrument or track with silence in it). The file should be in .mp3 or .wav format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JXB3HnLjP-j"
   },
   "source": [
    "##Process audio\n",
    "The next step process our audio files. Edit the first line of the next cell to point to your audio file. The run the cell after that to process the audio and generate a graph of the volume data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KW4dQcTUB1q2"
   },
   "outputs": [],
   "source": [
    "# stylegan3 모듈을 불러오는 방법\n",
    "import sys # 파이썬을 설치할 때 함께 설치 되는 라이브러리 모듈\n",
    "sys.path.append('/content/stylegan3') # sys.path.append를 이용해서 /content/stylegan3 라는 디렉토리를 sys.path에 추가하여 모듈을 불러와서 사용할 수 있도록 하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\r\n",
      "To initialize your shell, run\r\n",
      "\r\n",
      "    $ conda init <SHELL_NAME>\r\n",
      "\r\n",
      "Currently supported shells are:\r\n",
      "  - bash\r\n",
      "  - fish\r\n",
      "  - tcsh\r\n",
      "  - xonsh\r\n",
      "  - zsh\r\n",
      "  - powershell\r\n",
      "\r\n",
      "See 'conda init --help' for more information and options.\r\n",
      "\r\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# stylegan3 환경에 깔아야 하는 파일 설치하는 코드\n",
    "!conda activate stylegan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/roughideal_gmail_com/stylegan3\n"
     ]
    }
   ],
   "source": [
    "# 아래 코드를 돌리기 전에 사용해야하는 코드 (그래야 dnnlib 에서 오류가 나오지 않습니다.)\n",
    "%cd stylegan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMKDAPieT7XE",
    "outputId": "222f415d-1802-4d38-f91e-73b43a837d96"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import savgol_filter # Savitzky–Golay 필터는 데이터를 평활화, 즉 신호 경향을 왜곡하지 않고 데이터의 정밀도를 높이기 위해 디지털 데이터 포인트 세트에 적용 할 수있는 디지털 필터입니다.\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import moviepy.editor\n",
    "\n",
    "import dnnlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import pickle\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GbsE9p-2Vl3B"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "i8TWpZNjTwWa"
   },
   "outputs": [],
   "source": [
    "# wav_filename 경로 설정 코드\n",
    "wav_filename = \"/home/roughideal_gmail_com/forest10s.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "gopdtgoA0dfg",
    "outputId": "0977d592-1f31-409c-a7d7-6c297e1987bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames :  244\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio = {}\n",
    "fps = 24\n",
    "\n",
    "# 파형 민감도 설정 / polyorder must be smaller than window_length\n",
    "window_length = 111 # FFT (FFT란 Fast Fourier Transform의 약자이며, 쉽게 말해서 빠르게 Fourier를 변환하는 방식을 할 때 수행할 시간 간격을 의미합니다.\n",
    "polyorder = 5 # 정확하게 무슨 의미인지는 모르겠지만, 7 이상의 값에서 wave에서 flat 한 영역이 보입니다.\n",
    "activeness = 1/2\n",
    "\n",
    "if not os.path.exists(wav_filename):\n",
    "    audio_clip = moviepy.editor.AudioFileClip(wav_filename)\n",
    "    audio_clip.write_audiofile(wav_filename, fps=44100, nbytes=2, codec='pcm_s16le')\n",
    "track_name = os.path.basename(wav_filename)[:-4]\n",
    "rate, signal = wavfile.read(wav_filename)\n",
    "signal = np.mean(signal, axis=1) # to mono\n",
    "signal = np.abs(signal)\n",
    "# seed = signal.shape[0]\n",
    "duration = signal.shape[0] / rate\n",
    "frames = int(np.ceil(duration * fps))\n",
    "samples_per_frame = signal.shape[0] / frames\n",
    "audio[track_name] = np.zeros(frames, dtype=signal.dtype)\n",
    "for frame in range(frames):\n",
    "    start = int(round(frame * samples_per_frame))\n",
    "    stop = int(round((frame + 1) * samples_per_frame))  \n",
    "    audio[track_name][frame] = np.mean(signal[start:stop], axis=0)\n",
    "\n",
    "audio[track_name] = savgol_filter(audio[track_name], window_length, polyorder)\n",
    "audio[track_name] = audio[track_name] / max(audio[track_name])\n",
    "audio[track_name] = audio[track_name] ** activeness\n",
    "\n",
    "print(\"Total frames : \", frames)\n",
    "\n",
    "for track in sorted(audio.keys()):\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.title(track)\n",
    "    plt.plot(audio[track])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.savefig(f'../{track}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONTlyw6ZUNQl"
   },
   "source": [
    "Run the next cell to define some functions we’ll need to use to generate our inference images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KyCHTNpzPuWL"
   },
   "outputs": [],
   "source": [
    "def generate_zs_from_seeds(seeds,Gs):\n",
    "    zs = []\n",
    "    for seed_idx, seed in enumerate(seeds): # seed 인덱스, 값\n",
    "        rnd = np.random.RandomState(seed) # Random 생성값\n",
    "        z = rnd.randn(1, Gs.mapping.z_dim) # [minibatch, component] 가우시안 정규 분포 난수 생성\n",
    "        zs.append(z)\n",
    "    return zs\n",
    "\n",
    "def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n",
    "  latent = torch.from_numpy(latent).to(device)\n",
    "  dlatent = Gs.mapping(latent, 0) # [seed, layer, component]\n",
    "  dlatent_avg = Gs.mapping.w_avg # [component]\n",
    "  for i in range(truncation_cutoff):\n",
    "    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n",
    "    \n",
    "  return dlatent\n",
    "\n",
    "def generate_images_in_w_space(dlatents, truncation_psi,folder='random'):\n",
    "    # Gs_kwargs = dnnlib.EasyDict()\n",
    "    # Gs_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "    # Gs_kwargs.randomize_noise = False\n",
    "    # Gs_kwargs.truncation_psi = truncation_psi\n",
    "    dlatent_avg = Gs.mapping.w_avg # [component]\n",
    "\n",
    "    if folder == 'random':\n",
    "      temp_dir = 'frames%06d'%int(1000000*random.random())\n",
    "    else:\n",
    "      temp_dir = folder\n",
    "    os.system('mkdir %s'%temp_dir)\n",
    "\n",
    "    for row, dlatent in enumerate(dlatents):\n",
    "        print('Generating image for step %d/%d ...' % (row, len(dlatents)))\n",
    "        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n",
    "        dl = (dlatent-dlatent_avg)*truncation_psi + dlatent_avg  # dl이 왜 들어가나요?? 내부 네트워크에서 karg를 줬을 때 저렇게 수행이 됩니다. <- truncation에 대해서\n",
    "        row_images = Gs.synthesis(dlatent) # dlatent -> dl 로 변경 시 truncation_psi이 적용 된 상태 -> mapping 에 넣을 때 저 kwargs 값을 주면 됩니다.\n",
    "        row_image = (row_images.permute(0,2,3,1)*127.5+128).clamp(0,255).to(torch.uint8)\n",
    "        row_image = row_image.squeeze(0).cpu().numpy()\n",
    "        PIL.Image.fromarray(row_image, 'RGB').save('%s/frame%05d.png' % (temp_dir, row))\n",
    "\n",
    "def load_networks(path):\n",
    "    with open(path, 'rb') as stream:\n",
    "        Gs = pickle.load(stream)['G_ema'].to(device)\n",
    "    Gs.eval()\n",
    "    return Gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kByt3G4yUp02"
   },
   "source": [
    "## Generate Images\n",
    "\n",
    "### Use Volume to interpolate between two seeds\n",
    "The next cell will take two seed values and do a linear interpolation of them using the volume from your audio. When the audio is silent, it will be the first seed you list. When it is at its loudest it will be the second. Everything in between will be an interpolated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_utils\n",
      "  Downloading torch-utils-0.1.2.tar.gz (4.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in ./anaconda3/lib/python3.9/site-packages (from torch_utils) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.9/site-packages (from torch->torch_utils) (3.10.0.2)\n",
      "Building wheels for collected packages: torch-utils\n",
      "  Building wheel for torch-utils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-utils: filename=torch_utils-0.1.2-py3-none-any.whl size=6201 sha256=d64093154406ffcaf566fec7f9a0117328fab11faca2349b3c981a55524b87f2\n",
      "  Stored in directory: /root/.cache/pip/wheels/b9/ae/b4/56ed29da706ea5e0f79157a9b158aad24bfabd045ef42eed75\n",
      "Successfully built torch-utils\n",
      "Installing collected packages: torch-utils\n",
      "Successfully installed torch-utils-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/roughideal_gmail_com/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # 초기에 설치해주어야 하는 거 이 코드는 돌리실 때 돌리지 않으셔도 됩니다.\n",
    "# !pip install torch_utils\n",
    "# !pip install torch_utils.persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSPddCx9iVSR",
    "outputId": "6b8fe827-1008-49be-8fe7-0d4af2c7470d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Generating image for step 0/244 ...\n",
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
      "Generating image for step 1/244 ...\n",
      "Generating image for step 2/244 ...\n",
      "Generating image for step 3/244 ...\n",
      "Generating image for step 4/244 ...\n",
      "Generating image for step 5/244 ...\n",
      "Generating image for step 6/244 ...\n",
      "Generating image for step 7/244 ...\n",
      "Generating image for step 8/244 ...\n",
      "Generating image for step 9/244 ...\n",
      "Generating image for step 10/244 ...\n",
      "Generating image for step 11/244 ...\n",
      "Generating image for step 12/244 ...\n",
      "Generating image for step 13/244 ...\n",
      "Generating image for step 14/244 ...\n",
      "Generating image for step 15/244 ...\n",
      "Generating image for step 16/244 ...\n",
      "Generating image for step 17/244 ...\n",
      "Generating image for step 18/244 ...\n",
      "Generating image for step 19/244 ...\n",
      "Generating image for step 20/244 ...\n",
      "Generating image for step 21/244 ...\n",
      "Generating image for step 22/244 ...\n",
      "Generating image for step 23/244 ...\n",
      "Generating image for step 24/244 ...\n",
      "Generating image for step 25/244 ...\n",
      "Generating image for step 26/244 ...\n",
      "Generating image for step 27/244 ...\n",
      "Generating image for step 28/244 ...\n",
      "Generating image for step 29/244 ...\n",
      "Generating image for step 30/244 ...\n",
      "Generating image for step 31/244 ...\n",
      "Generating image for step 32/244 ...\n",
      "Generating image for step 33/244 ...\n",
      "Generating image for step 34/244 ...\n",
      "Generating image for step 35/244 ...\n",
      "Generating image for step 36/244 ...\n",
      "Generating image for step 37/244 ...\n",
      "Generating image for step 38/244 ...\n",
      "Generating image for step 39/244 ...\n",
      "Generating image for step 40/244 ...\n",
      "Generating image for step 41/244 ...\n",
      "Generating image for step 42/244 ...\n",
      "Generating image for step 43/244 ...\n",
      "Generating image for step 44/244 ...\n",
      "Generating image for step 45/244 ...\n",
      "Generating image for step 46/244 ...\n",
      "Generating image for step 47/244 ...\n",
      "Generating image for step 48/244 ...\n",
      "Generating image for step 49/244 ...\n",
      "Generating image for step 50/244 ...\n",
      "Generating image for step 51/244 ...\n",
      "Generating image for step 52/244 ...\n",
      "Generating image for step 53/244 ...\n",
      "Generating image for step 54/244 ...\n",
      "Generating image for step 55/244 ...\n",
      "Generating image for step 56/244 ...\n",
      "Generating image for step 57/244 ...\n",
      "Generating image for step 58/244 ...\n",
      "Generating image for step 59/244 ...\n",
      "Generating image for step 60/244 ...\n",
      "Generating image for step 61/244 ...\n",
      "Generating image for step 62/244 ...\n",
      "Generating image for step 63/244 ...\n",
      "Generating image for step 64/244 ...\n",
      "Generating image for step 65/244 ...\n",
      "Generating image for step 66/244 ...\n",
      "Generating image for step 67/244 ...\n",
      "Generating image for step 68/244 ...\n",
      "Generating image for step 69/244 ...\n",
      "Generating image for step 70/244 ...\n",
      "Generating image for step 71/244 ...\n",
      "Generating image for step 72/244 ...\n",
      "Generating image for step 73/244 ...\n",
      "Generating image for step 74/244 ...\n",
      "Generating image for step 75/244 ...\n",
      "Generating image for step 76/244 ...\n",
      "Generating image for step 77/244 ...\n",
      "Generating image for step 78/244 ...\n",
      "Generating image for step 79/244 ...\n",
      "Generating image for step 80/244 ...\n",
      "Generating image for step 81/244 ...\n",
      "Generating image for step 82/244 ...\n",
      "Generating image for step 83/244 ...\n",
      "Generating image for step 84/244 ...\n",
      "Generating image for step 85/244 ...\n",
      "Generating image for step 86/244 ...\n",
      "Generating image for step 87/244 ...\n",
      "Generating image for step 88/244 ...\n",
      "Generating image for step 89/244 ...\n",
      "Generating image for step 90/244 ...\n",
      "Generating image for step 91/244 ...\n",
      "Generating image for step 92/244 ...\n",
      "Generating image for step 93/244 ...\n",
      "Generating image for step 94/244 ...\n",
      "Generating image for step 95/244 ...\n",
      "Generating image for step 96/244 ...\n",
      "Generating image for step 97/244 ...\n",
      "Generating image for step 98/244 ...\n",
      "Generating image for step 99/244 ...\n",
      "Generating image for step 100/244 ...\n",
      "Generating image for step 101/244 ...\n",
      "Generating image for step 102/244 ...\n",
      "Generating image for step 103/244 ...\n",
      "Generating image for step 104/244 ...\n",
      "Generating image for step 105/244 ...\n",
      "Generating image for step 106/244 ...\n",
      "Generating image for step 107/244 ...\n",
      "Generating image for step 108/244 ...\n",
      "Generating image for step 109/244 ...\n",
      "Generating image for step 110/244 ...\n",
      "Generating image for step 111/244 ...\n",
      "Generating image for step 112/244 ...\n",
      "Generating image for step 113/244 ...\n",
      "Generating image for step 114/244 ...\n",
      "Generating image for step 115/244 ...\n",
      "Generating image for step 116/244 ...\n",
      "Generating image for step 117/244 ...\n",
      "Generating image for step 118/244 ...\n",
      "Generating image for step 119/244 ...\n",
      "Generating image for step 120/244 ...\n",
      "Generating image for step 121/244 ...\n",
      "Generating image for step 122/244 ...\n",
      "Generating image for step 123/244 ...\n",
      "Generating image for step 124/244 ...\n",
      "Generating image for step 125/244 ...\n",
      "Generating image for step 126/244 ...\n",
      "Generating image for step 127/244 ...\n",
      "Generating image for step 128/244 ...\n",
      "Generating image for step 129/244 ...\n",
      "Generating image for step 130/244 ...\n",
      "Generating image for step 131/244 ...\n",
      "Generating image for step 132/244 ...\n",
      "Generating image for step 133/244 ...\n",
      "Generating image for step 134/244 ...\n",
      "Generating image for step 135/244 ...\n",
      "Generating image for step 136/244 ...\n",
      "Generating image for step 137/244 ...\n",
      "Generating image for step 138/244 ...\n",
      "Generating image for step 139/244 ...\n",
      "Generating image for step 140/244 ...\n",
      "Generating image for step 141/244 ...\n",
      "Generating image for step 142/244 ...\n",
      "Generating image for step 143/244 ...\n",
      "Generating image for step 144/244 ...\n",
      "Generating image for step 145/244 ...\n",
      "Generating image for step 146/244 ...\n",
      "Generating image for step 147/244 ...\n",
      "Generating image for step 148/244 ...\n",
      "Generating image for step 149/244 ...\n",
      "Generating image for step 150/244 ...\n",
      "Generating image for step 151/244 ...\n",
      "Generating image for step 152/244 ...\n",
      "Generating image for step 153/244 ...\n",
      "Generating image for step 154/244 ...\n",
      "Generating image for step 155/244 ...\n",
      "Generating image for step 156/244 ...\n",
      "Generating image for step 157/244 ...\n",
      "Generating image for step 158/244 ...\n",
      "Generating image for step 159/244 ...\n",
      "Generating image for step 160/244 ...\n",
      "Generating image for step 161/244 ...\n",
      "Generating image for step 162/244 ...\n",
      "Generating image for step 163/244 ...\n",
      "Generating image for step 164/244 ...\n",
      "Generating image for step 165/244 ...\n",
      "Generating image for step 166/244 ...\n",
      "Generating image for step 167/244 ...\n",
      "Generating image for step 168/244 ...\n",
      "Generating image for step 169/244 ...\n",
      "Generating image for step 170/244 ...\n",
      "Generating image for step 171/244 ...\n",
      "Generating image for step 172/244 ...\n",
      "Generating image for step 173/244 ...\n",
      "Generating image for step 174/244 ...\n",
      "Generating image for step 175/244 ...\n",
      "Generating image for step 176/244 ...\n",
      "Generating image for step 177/244 ...\n",
      "Generating image for step 178/244 ...\n",
      "Generating image for step 179/244 ...\n",
      "Generating image for step 180/244 ...\n",
      "Generating image for step 181/244 ...\n",
      "Generating image for step 182/244 ...\n",
      "Generating image for step 183/244 ...\n",
      "Generating image for step 184/244 ...\n",
      "Generating image for step 185/244 ...\n",
      "Generating image for step 186/244 ...\n",
      "Generating image for step 187/244 ...\n",
      "Generating image for step 188/244 ...\n",
      "Generating image for step 189/244 ...\n",
      "Generating image for step 190/244 ...\n",
      "Generating image for step 191/244 ...\n",
      "Generating image for step 192/244 ...\n",
      "Generating image for step 193/244 ...\n",
      "Generating image for step 194/244 ...\n",
      "Generating image for step 195/244 ...\n",
      "Generating image for step 196/244 ...\n",
      "Generating image for step 197/244 ...\n",
      "Generating image for step 198/244 ...\n",
      "Generating image for step 199/244 ...\n",
      "Generating image for step 200/244 ...\n",
      "Generating image for step 201/244 ...\n",
      "Generating image for step 202/244 ...\n",
      "Generating image for step 203/244 ...\n",
      "Generating image for step 204/244 ...\n",
      "Generating image for step 205/244 ...\n",
      "Generating image for step 206/244 ...\n",
      "Generating image for step 207/244 ...\n",
      "Generating image for step 208/244 ...\n",
      "Generating image for step 209/244 ...\n",
      "Generating image for step 210/244 ...\n",
      "Generating image for step 211/244 ...\n",
      "Generating image for step 212/244 ...\n",
      "Generating image for step 213/244 ...\n",
      "Generating image for step 214/244 ...\n",
      "Generating image for step 215/244 ...\n",
      "Generating image for step 216/244 ...\n",
      "Generating image for step 217/244 ...\n",
      "Generating image for step 218/244 ...\n",
      "Generating image for step 219/244 ...\n",
      "Generating image for step 220/244 ...\n",
      "Generating image for step 221/244 ...\n",
      "Generating image for step 222/244 ...\n",
      "Generating image for step 223/244 ...\n",
      "Generating image for step 224/244 ...\n",
      "Generating image for step 225/244 ...\n",
      "Generating image for step 226/244 ...\n",
      "Generating image for step 227/244 ...\n",
      "Generating image for step 228/244 ...\n",
      "Generating image for step 229/244 ...\n",
      "Generating image for step 230/244 ...\n",
      "Generating image for step 231/244 ...\n",
      "Generating image for step 232/244 ...\n",
      "Generating image for step 233/244 ...\n",
      "Generating image for step 234/244 ...\n",
      "Generating image for step 235/244 ...\n",
      "Generating image for step 236/244 ...\n",
      "Generating image for step 237/244 ...\n",
      "Generating image for step 238/244 ...\n",
      "Generating image for step 239/244 ...\n",
      "Generating image for step 240/244 ...\n",
      "Generating image for step 241/244 ...\n",
      "Generating image for step 242/244 ...\n",
      "Generating image for step 243/244 ...\n"
     ]
    }
   ],
   "source": [
    "# z noise blend\n",
    "\n",
    "network_pkl = '/home/roughideal_gmail_com/awesome_beach.pkl'\n",
    "seeds = [10, 40, 160, 640, 2560]\n",
    "seeds_t = [20, 80, 320, 1280, 5120]\n",
    "truncation_value = 0.7 # 크면 클 수록 변화 되는 정도가 큰 거 같은 느낌??\n",
    "truncation_psi = 0.7 # 작으면 작을 수록 파도가 잔잔해집니다.\n",
    "truncation_cutoff = 5 # 아직은 value를 변경함에 따라 어떤 상관관계를 보이는 지 찾지 못 했습니다.\n",
    "flow_speed = 1.5\n",
    "flow_energy = 1\n",
    "\n",
    "# seeds10~5120,value0.7,psi0.7,cutoff7,speed1.5,flow_energy1\n",
    "\n",
    "# you probably won't need to edit anything below this\n",
    "Gs = load_networks(network_pkl)\n",
    "\n",
    "# Gs_kwargs = dnnlib.EasyDict()\n",
    "# Gs_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "# Gs_kwargs.randomize_noise = False\n",
    "# Gs_syn_kwargs = dnnlib.EasyDict()\n",
    "# Gs_syn_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "# Gs_syn_kwargs.randomize_noise = False\n",
    "# Gs_syn_kwargs.minibatch_size = 4\n",
    "\n",
    "w_avg = Gs.mapping.w_avg\n",
    "\n",
    "def get_ws(n, frames, seed):\n",
    "    filename = f'../ws_{n}_{frames}_{seed}.npy'\n",
    "    if not os.path.exists(filename):\n",
    "        src_ws = np.random.RandomState(seed).randn(n, 512)\n",
    "        ws = np.empty((frames, 512))\n",
    "        for i in range(512):\n",
    "            x = np.linspace(0, 3*frames, 3*len(src_ws), endpoint=False)\n",
    "            y = np.tile(src_ws[:, i], 3)\n",
    "            x_ = np.linspace(0, 3*frames, 3*frames, endpoint=False)\n",
    "            y_ = interp1d(x, y, kind='quadratic', fill_value='extrapolate')(x_)\n",
    "            ws[:, i] = y_[frames:2*frames]\n",
    "        np.save(filename, ws)\n",
    "    else:\n",
    "        ws = np.load(filename)\n",
    "    return ws\n",
    "\n",
    "def lerp_t(ends_t):\n",
    "    ends_t_lerp = []\n",
    "    for f in range(frames):\n",
    "        y_list = []\n",
    "        for i in range(len(seeds_t)):\n",
    "            y = 1 - abs(1/frames*(f-i/len(seeds_t)*frames))\n",
    "            y_list.append(y)\n",
    "        y_list = np.divide(y_list, sum(y_list))\n",
    "        temp = y_list[i]*ends_t[i]\n",
    "        ends_t_lerp.append(temp)\n",
    "    return ends_t_lerp\n",
    "\n",
    "\n",
    "def lerp(v0, v1, f, t): # 시드에 따라 움직임이 생성\n",
    "    # return (v0*(1.0-f)+v1*f)\n",
    "    return v0*(1.0-(abs(math.sin(flow_speed * ((f+1)**flow_energy) * math.pi * t / 360)))) + v1*(abs(math.sin(flow_speed * ((f+1)**flow_energy) * math.pi * t / 360)))\n",
    "\n",
    "\n",
    "ends = generate_zs_from_seeds(seeds,Gs) # 가우시안 정규 분포 난수\n",
    "ends_t = generate_zs_from_seeds(seeds_t,Gs) # 시간값에 따른 난수\n",
    "ends_b = []\n",
    "ends_lerp = lerp_t(ends)\n",
    "ends_t_lerp = lerp_t(ends_t)\n",
    "\n",
    "for f in range(frames):\n",
    "    ends_b.append(lerp(ends_t_lerp[f],ends_lerp[f],audio[track_name][f],f))\n",
    "\n",
    "ends_w = []\n",
    "\n",
    "for e in range(len(ends_b)):\n",
    "    ends_w.append(convertZtoW(ends_b[e],1))\n",
    "\n",
    "vectors = ends_w\n",
    "\n",
    "generate_images_in_w_space(vectors,truncation_value,'frames_test03')\n",
    "\n",
    "# for e in range(len(ends)):\n",
    "#   ends_w.append(convertZtoW(ends[e],truncation_psi,truncation_cutoff)) # latent Z -> W 로 매핑, truncation 을 사용하지 않기 위해서 0.5 -> 1,0 으로 변경, 노이즈에 따라서 얼마나 바뀌는가?\n",
    "\n",
    "# for e in range(len(ends_t)):\n",
    "#   ends_w_t.append(convertZtoW(ends_t[e],truncation_psi,truncation_cutoff))\n",
    "\n",
    "# vectors = [] # 시드별로 프레임 보간\n",
    "# vectors_blending_A = []\n",
    "# vectors_blending_B = []\n",
    "\n",
    "# for i in range((len(seeds)-1)):\n",
    "#   count = 0\n",
    "\n",
    "#   for f in range((frames//(len(seeds)-1))+1):\n",
    "#     vectors.append(lerp(ends_w[i],ends_w[i+1],ends_w_t[i],ends_w_t[i+1],audio[track_name][f],f))\n",
    "#     if f <= ((frames//(len(seeds)-1))+1)*0.1:\n",
    "#       vectors_blending_A.append(lerp(ends_w[i],ends_w[i+1],ends_w_t[i],ends_w_t[i+1],audio[track_name][f],f))\n",
    "#     if f >= ((frames//(len(seeds)-1))+1)*0.9:\n",
    "#       vectors_blending_B.append(lerp(ends_w[i],ends_w[i+1],ends_w_t[i],ends_w_t[i+1],audio[track_name][f],f))\n",
    "\n",
    "# generate_images_in_w_space(vectors,truncation_value,'frames_test11')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOkh2DZpV-9W"
   },
   "source": [
    "### Combine the frames into a video and add the audio track back to it\n",
    "\n",
    "There’s probably a cleaner way to do this all in moviepy but I’m being lazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPClSNx_Atn-",
    "outputId": "2c90a24a-1378-4418-800a-2b121da38971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.4-1ubuntu0.1 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.3.0-10ubuntu2)\n",
      "  configuration: --prefix=/usr --extra-version=1ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from '/home/roughideal_gmail_com/stylegan3/frames_test03/frame%05d.png':\n",
      "  Duration: 00:00:09.76, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 256x256, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mprofile High, level 1.3\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/roughideal_gmail_com/sound-react-volume-test-awesome1.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 256x256, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  244 fps=0.0 q=-1.0 Lsize=     606kB time=00:00:10.04 bitrate= 494.4kbits/s speed=11.2x    \n",
      "video:603kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.503208%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mframe I:2     Avg QP:18.44  size:  3157\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mframe P:135   Avg QP:25.49  size:  4308\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mframe B:107   Avg QP:30.49  size:   269\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mconsecutive B-frames: 36.1% 12.3% 12.3% 39.3%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mmb I  I16..4: 50.2% 40.6%  9.2%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mmb P  I16..4:  0.0%  1.5%  0.4%  P16..4: 40.4% 25.7% 19.8%  0.0%  0.0%    skip:12.1%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 34.2%  2.5%  0.7%  direct: 1.7%  skip:60.8%  L0:17.1% L1:38.6% BI:44.3%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0m8x8 transform intra:61.3% inter:51.8%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mcoded y,uvDC,uvAC intra: 76.2% 39.4% 2.5% inter: 40.5% 13.5% 0.1%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mi16 v,h,dc,p: 92%  0%  6%  2%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  8% 15% 15%  8% 11%  9% 13%  8% 14%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 13% 16%  9% 13%  9% 12%  7% 11%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mi8c dc,h,v,p: 75% 13% 10%  2%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mWeighted P-Frames: Y:65.9% UV:20.7%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mref P L0: 51.3% 29.0% 16.2%  2.5%  1.1%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mref B L0: 92.6%  4.3%  3.1%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mref B L1: 96.0%  4.0%\n",
      "\u001b[1;36m[libx264 @ 0x562c91c09b00] \u001b[0mkb/s:485.31\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -r 24 -i /home/roughideal_gmail_com/stylegan3/frames_test03/frame%05d.png -vcodec libx264 -pix_fmt yuv420p /home/roughideal_gmail_com/sound-react-volume-test-awesome1.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7TUwqrTi4y-",
    "outputId": "97f7d981-9e82-43e8-943f-e371c7468b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/roughideal_gmail_com/audio_reactive_wave_sample_test-awesome.mp4.\n",
      "MoviePy - Writing audio in audio_reactive_wave_sample_test-awesomeTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/roughideal_gmail_com/audio_reactive_wave_sample_test-awesome.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/roughideal_gmail_com/audio_reactive_wave_sample_test-awesome.mp4\n"
     ]
    }
   ],
   "source": [
    "# output file name\n",
    "mp4_filename = '/home/roughideal_gmail_com/audio_reactive_wave_sample_test-awesome.mp4' # \n",
    "# video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n",
    "video_clip = moviepy.editor.VideoFileClip('/home/roughideal_gmail_com/sound-react-volume-test-awesome1.mp4')\n",
    "audio_clip_i = moviepy.editor.AudioFileClip('/home/roughideal_gmail_com/forest10s.wav')\n",
    "video_clip = video_clip.set_audio(audio_clip_i)\n",
    "video_clip.write_videofile(mp4_filename, fps=fps, codec='libx264', audio_codec='aac', bitrate='8M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibDI8hGWWPD0"
   },
   "source": [
    "### Use Volume to control truncation\n",
    "In this example, we’ll use almost the same technique but use volume to change the truncation value. \n",
    "\n",
    "It’s helpful that both interpolation and truncation are essentially 0.0 to 1.0. This matches the volume signal’s output, but what if we wanted to alter it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifbLsbOcXsgy"
   },
   "outputs": [],
   "source": [
    "seeds=[135]\n",
    "\n",
    "seed_z = generate_zs_from_seeds(seeds,Gs)\n",
    "\n",
    "#Gs_kwargs = dnnlib.EasyDict()\n",
    "#Gs_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "#Gs_kwargs.randomize_noise = False\n",
    "\n",
    "rnd = np.random.RandomState(seeds[0])\n",
    "\n",
    "#temp_dir = '%s-trunc_frames%06d'%(track_name,int(1000000*random.random()))\n",
    "temp_dir = 's-trunc_frames2'\n",
    "os.system('mkdir %s'%temp_dir)\n",
    "\n",
    "for f in range(frames):\n",
    "  print('Rendering frame %d/%d ...' % (f,frames))\n",
    "  Gs_kwargs.truncation_psi = audio[track_name][f]\n",
    "  #set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
    "  images = Gs(torch.from_numpy(seed_z[0]).to(device), 0) # [minibatch, height, width, channel]\n",
    "  image = (images.permute(0,2,3,1)*127.5+128).clamp(0,255).to(torch.uint8)\n",
    "  image = image.squeeze(0).cpu().numpy()\n",
    "  PIL.Image.fromarray(image, 'RGB').save('%s/frame%05d.png' % (temp_dir,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gw3negi0e7ll"
   },
   "outputs": [],
   "source": [
    "!ffmpeg -r 24 -i /content/s-trunc_frames2/frame%05d.png -vcodec libx264 -pix_fmt yuv420p /content/sound-truncation-volume2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1AC2mF1bwKP"
   },
   "outputs": [],
   "source": [
    "mp4_filename = '/content/audio_reactive_truncation_wave2.mp4'\n",
    "# video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n",
    "video_clip = moviepy.editor.VideoFileClip('/content/sound-truncation-volume2.mp4')\n",
    "audio_clip_i = moviepy.editor.AudioFileClip('/content/ocean-waves-1.wav')\n",
    "video_clip = video_clip.set_audio(audio_clip_i)\n",
    "video_clip.write_videofile(mp4_filename, fps=fps, codec='libx264', audio_codec='aac', bitrate='8M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nR6VU8QJb4cB"
   },
   "outputs": [],
   "source": [
    "seeds=[10]\n",
    "\n",
    "seed_z = generate_zs_from_seeds(seeds,Gs)\n",
    "\n",
    "Gs_kwargs = dnnlib.EasyDict()\n",
    "Gs_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "Gs_kwargs.randomize_noise = False\n",
    "\n",
    "rnd = np.random.RandomState(seeds[0])\n",
    "temp_dir = '%s-trunc_frames%06d'%(track_name,int(1000000*random.random()))\n",
    "os.system('mkdir %s'%temp_dir)\n",
    "\n",
    "for f in range(frames):\n",
    "  print('Rendering frame %d/%d ...' % (f,frames))\n",
    "\n",
    "  #edit the next line to alter the volume signal\n",
    "  # new_truncation_value = audio[track_name][f]*2 #multiply by 2 (0.0 to 2.0 for volume signal/truncation value now)\n",
    "  new_truncation_value = (audio[track_name][f]-0.5)*2 #(-1.0 to 1.0 for volume signal/truncation value now)\n",
    "\n",
    "  Gs_kwargs.truncation_psi = new_truncation_value\n",
    "  set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
    "  images = Gs.run(seed_z[0], None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
    "  PIL.Image.fromarray(images[0], 'RGB').save('%s/frame%05d.png' % (temp_dir,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRdc-crzdkDm"
   },
   "outputs": [],
   "source": [
    "!ffmpeg -r 60 -i /content/stylegan2/pleasureisallmine_01-stereo-trunc_frames623374/frame%05d.png -vcodec libx264 -pix_fmt yuv420p /content/sound-truncation-volume.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgezjUH3flxa"
   },
   "outputs": [],
   "source": [
    "mp4_filename = '../volume-trunc-test-v3.mp4'\n",
    "# video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n",
    "video_clip = moviepy.editor.VideoFileClip('/content/sound-truncation-volume.mp4')\n",
    "audio_clip_i = moviepy.editor.AudioFileClip('/content/stylegan2/pleasureisallmine_01-stereo.wav')\n",
    "video_clip = video_clip.set_audio(audio_clip_i)\n",
    "video_clip.write_videofile(mp4_filename, fps=fps, codec='libx264', audio_codec='aac', bitrate='8M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_78NFCdqL68"
   },
   "source": [
    "## Using feature vectors\n",
    "\n",
    "Let’s look at an example using a feature vector. In this case we’ll just use the straight audio signal.\n",
    "\n",
    "Upload your feature vector to Colab and then reference it’s location with a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl5w7TaLxldW"
   },
   "outputs": [],
   "source": [
    "network_pkl = \"/content/ffhq.pkl\"\n",
    "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
    "\n",
    "Gs_kwargs = dnnlib.EasyDict()\n",
    "Gs_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "Gs_kwargs.randomize_noise = False\n",
    "Gs_syn_kwargs = dnnlib.EasyDict()\n",
    "Gs_syn_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "Gs_syn_kwargs.randomize_noise = False\n",
    "Gs_syn_kwargs.minibatch_size = 4\n",
    "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
    "w_avg = Gs.get_var('dlatent_avg')\n",
    "\n",
    "def generate_mov(seed, truncation, direction_vec, scale, n_frames, out_name = 'out', noise_spec = None, loop=True):\n",
    "  \"\"\"Generates a mov moving back and forth along the chosen direction vector\"\"\"\n",
    "  # Example of reading a generated set of images, and storing as MP4.\n",
    "  %mkdir out\n",
    "  movieName = f'out/{out_name}.mp4'\n",
    "  offset = -10\n",
    "  step = 20 / n_frames\n",
    "  imgs = []\n",
    "  for i in range(n_frames):\n",
    "    print(f'{i} / {n_frames}')\n",
    "    \n",
    "    \n",
    "    batch_size = 1\n",
    "    all_seeds = [seed] * batch_size\n",
    "    all_z = np.stack([np.random.RandomState(seed).randn(*Gs.input_shape[1:]) for seed in all_seeds]) # [minibatch, component]\n",
    "    all_w = Gs.components.mapping.run(all_z, None) # [minibatch, layer, component]\n",
    "    if truncation != 1:\n",
    "        w_avg = Gs.get_var('dlatent_avg')\n",
    "        all_w = w_avg + (all_w - w_avg) * truncation # [minibatch, layer, component]\n",
    "    all_w += direction_vec * offset * scale\n",
    "    all_images = Gs.components.synthesis.run(all_w, **Gs_syn_kwargs)\n",
    "    #save image and display\n",
    "    final_im = PIL.Image.fromarray(np.median(all_images, axis=0).astype(np.uint8))\n",
    "    imgs.append(final_im)\n",
    "    #increase offset\n",
    "    offset += step\n",
    "  if loop:\n",
    "    imgs += imgs[::-1]\n",
    "  with imageio.get_writer(movieName, mode='I') as writer:\n",
    "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
    "        writer.append_data(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PA40ehfqy2S2"
   },
   "outputs": [],
   "source": [
    "seed = 10 # starting seed (will appear at 0.5)\n",
    "truncation = 0.7\n",
    "feature = '/content/profile-c2.npy'\n",
    "feature_range = 2 # feature_range maps the range of change in features \n",
    "scale = 1 # scale multiples the strength of the feature (1 is prob fine)\n",
    "\n",
    "#-------------------\n",
    "\n",
    "Gs_kwargs = dnnlib.EasyDict()\n",
    "Gs_kwargs.output_transform = dict(func=convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "Gs_kwargs.randomize_noise = False\n",
    "if truncation is not None:\n",
    "  Gs_kwargs.truncation_psi = truncation\n",
    "set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
    "w_avg = Gs.get_var('dlatent_avg')\n",
    "\n",
    "# get starting z and w\n",
    "rnd = np.random.RandomState(seed)\n",
    "z = rnd.randn(1, *Gs.input_shape[1:])\n",
    "w = Gs.components.mapping.run(z, None)\n",
    "\n",
    "# make dir\n",
    "feature_name=os.path.basename(feature)[:-4] \n",
    "dir = '%s_%s_range%02d_seed%05d'%(track_name,feature_name,feature_range,seed)\n",
    "os.system('mkdir %s'%dir)\n",
    "\n",
    "# setup\n",
    "feature_vec = np.load(feature)\n",
    "min_range = -feature_range\n",
    "max_range = feature_range\n",
    "offset = min_range #start value\n",
    "\n",
    "#generate frames\n",
    "for f in range(frames):\n",
    "  print('Rendering frame %d/%d ...' % (f,frames))\n",
    "\n",
    "  if truncation != 1:\n",
    "    w = w_avg + (w - w_avg) * truncation # [minibatch, layer, component]\n",
    "  \n",
    "  w += feature_vec * offset * scale\n",
    "\n",
    "  #save image and display\n",
    "  image = Gs.components.synthesis.run(w, **Gs_syn_kwargs)\n",
    "  PIL.Image.fromarray(image[0],'RGB').save('%s/frame%05d.png' % (dir,f))\n",
    "  \n",
    "  #increase offset\n",
    "  offset = lerp( min_range,max_range,audio[track_name][f] )\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hbk-mwtQ2oWj"
   },
   "outputs": [],
   "source": [
    "!ffmpeg -r 60 -i /content/stylegan2/pleasureisallmine_01-stereo_profile-c2_range02_seed00010/frame%05d.png -vcodec libx264 -pix_fmt yuv420p /content/sound-feature-volume-range2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnoVg2o0AE3_"
   },
   "outputs": [],
   "source": [
    "mp4_filename = '../volume-feature-test-range2.mp4'\n",
    "# video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n",
    "video_clip = moviepy.editor.VideoFileClip('/content/sound-feature-volume-range2.mp4')\n",
    "audio_clip_i = moviepy.editor.AudioFileClip('/content/stylegan2/pleasureisallmine_01-stereo.wav')\n",
    "video_clip = video_clip.set_audio(audio_clip_i)\n",
    "video_clip.write_videofile(mp4_filename, fps=fps, codec='libx264', audio_codec='aac', bitrate='8M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMyuqpcDBqQ3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20220218_StyleGAN3_Reactive_Audio_Ho.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
